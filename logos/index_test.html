<html xmlns="http://www.w3.org/1999/xhtml">
<head>
	<title>Hanbyul Joo</title>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<link rel="stylesheet" type="text/css" href="myStyle.css">

	<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-50740543-1', 'cmu.edu');
  ga('send', 'pageview');

	</script>
</head>

<body>
<table border="0" cellpadding="15" cellspacing="0" width="1000">
<tr>
<td>&nbsp;</td>
</tr>

<tr>
<td valign="top">
</td>
	<td valign="top">
		<table border="0" cellpadding="0" cellspacing="0" width="100%">
			<td align="left" width="50%">
			<img width="60" src="img/RI_logo.jpg">
			<p>
			<font size="+2">
			<b>Hanbyul Joo</b>
			</font>
			<br> Ph.D. student<br>
		 	   <a href="http://www.ri.cmu.edu">The Robotics Institute</a><br> 
			    <a href="http://www.cs.cmu.edu">School of Computer Science</a><br>
			    <a href="http://www.cmu.edu">Carnegie Mellon University</a><br>
			    Pittsburgh, PA 15213, USA<br><p>
			    Office: 201 Smith Hall<br>
			    Email:  hanbyulj at cs dot cmu dot edu <br><br>
			    <a href="CV_Hanbyul.pdf"> Curriculum Vitae</a> (updated in Jan. 2015)
			 <p>
		</td>
		<td  valign="bottom" align="left">
			<table>
			<tr>	
			<td> <img src="img/hbjoo.jpg" border=0 style="max-height: 300px; max-width: 300px;"></a> </td>
			<td> <img src="img/Dome_withME.jpg" border=0 style="max-height: 300px; max-width: 300px;"></a> </td>
			</tr>
			</table>
		</td>
		</table>

<p>
<hr size="1" align="left" noshade>
<p>
I am a Ph.D. student in the Robotics Institute at Carnegie Mellon University, under the supervision of <a href="http://www.cs.cmu.edu/~yaser/">Yaser Sheikh</a>. During summer 2015, I interned at Disney Research Zurich where I worked with <a href="https://graphics.ethz.ch/~dbeeler/">Thabo Beeler</a> and <a href="http://zurich.disneyresearch.com/derekbradley/">Derek Bradley</a>. Before joining CMU, I spent three years as a researcher at ETRI, a government-funded research organization in Korea. I received my M.S. in Electrical Engineering and B.S. in Computer Science, both
from KAIST, Korea. <a href="http://slsf.or.kr/community/HomeEn.screen"> The Samsung Scholarship </a> is supporting my graduate study. </p>

<h2>Research</h2>
<p>
My main research interests are in computer vision, computer graphics, and machine perception of social behavior. My work focuses on analyzing and understanding dynamic scenes using more than 500 synchronized cameras in the Panoptic Studio at CMU.
</p>

<br>
<p align="center">
<iframe width="560" height="315" src="//www.youtube.com/embed/xoPQnmkufeM?rel=0;3&amp;autohide=1&amp;showinfo=0" frameborder="0" allowfullscreen></iframe>
<h4 align="center"> Virtural Hanbyul in the Panoptic Studio</h4>
</p>


<h2>News</h2>

<ul>
<li> <p> <b> Sep 2016</b> Our <b>New</b> Panoptic Studio dataset website is open <a href="http://domedb.perception.cs.cmu.edu">(link)</a>. All dataset including videos from 500+ cameras and 3D skeltons reconstruction results, and a Toolbox are available. 
</p></li>

<li> <p> <b> Dec 2015</b> Our Social Motion Capture paper has been covered in the press: <a href="http://www.spiegel.de/netzwelt/gadgets/das-panoptische-studio-computer-entziffern-koerpersprache-a-1068155.html">SPIEGEL ONLINE (German)</a> and <a href="http://www.fastcodesign.com/3054561/inside-a-robot-eyeball-science-will-decode-our-body-language">Co.DESIGN</a>.
</p></li>


<li> <p> <b> Jun-Oct 2015</b> I have finished my internship at Disney Research Zurich, and came back to CMU. 
</p></li>

<li> <p> <b> Sep 2015</b> Our "Social Motion Capture" paper has been accepted as an oral presentation in ICCV 2015.
</p></li>

<li> <p> <b> Apr 2015</b> Our massively multiple view system and dynamic 3D reconstruction has been featured on the <a href="http://www.reuters.com/article/2015/04/29/us-usa-panoptic-studio-idUSKBN0NK09920150429">
<img src="http://www.cs.cmu.edu/~hanbyulj/logos/Reuters_logo.png" height="20"></div></a> and <a href="http://www.voanews.com/content/new-studio-yields-most-detailed-motion-capture-in-3d/2743347.html"><img src="http://www.cs.cmu.edu/~hanbyulj/logos/VOA_logo.png" height="17"></a>. Click the links to see the articles.

</p></li>

<li> <p> <b> Jan 2015</b> Our massively multiple view system and dynamic 3D reconstruction has been featured on <img src="http://img4.wikia.nocookie.net/__cb20091118171916/logopedia/images/4/49/Discovery_Channel_2009.png" height="17">, Daily Planet TV Show. You can see the segment in <a href="http://www.discovery.ca/dailyplanet"> Daily Planet website</a>. <!-- (Click "Segments", and select "Future tech: Panoptic Studio") </p></li -->


<li><p><b> Aug 2014</b> The dataset of our <a href="http://www.cs.cmu.edu/~hanbyulj/14/visibility.html"> dynamic 3D reconstruction paper </a> is now available in <a href="http://www.cs.cmu.edu/~hanbyulj/14/visibilityDataset.html">this webpage</a>.</p></li>

<li><p><b> July 2014</b> Our <a href="http://www.cs.cmu.edu/~hanbyulj/14/visibility.html"> dynamic 3D reconstruction paper </a> is featured on

<a href="http://spectrum.ieee.org/tech-talk/computing/software/camerafilled-dome-recreates-full-3d-motion-scenes"><img src="logos/IEEESpectrum.jpeg" height="17"></a>, 
 <a href="http://www.nbcnews.com/tech/innovation/camera-studded-dome-tracks-your-every-move-precision-n161541"><img src="logos/nbc-news.png" height="15"></a>, 
<a href="http://news.discovery.com/tech/gear-and-gadgets/dome-of-500-cameras-creates-amazing-3-d-flicks-140724.htm"><img src="logos/discovery.jpg" height="17"></a>, and so on. Check out the <a href="http://www.cs.cmu.edu/~hanbyulj/14/visibility.html">project page</a>. </p> </li>
</ul>

<h2>Publications</h2>
<table cellspacing="15">


<tr>
	<td width="30%">
	<img style="max-height: 200px; max-width: 250px;" src="img/007_bang.gif" border="0">
	</td>
	<td>
 		<p> <b>  Panoptic Studio: A Massively Multiview System for Social Motion Capture </b>
	<br>
	<b>Hanbyul Joo</b>, Hao Liu, Lei Tan, Lin Gui, Bart Nabbe, Iain Matthews, Takeo Kanade, Shohei Nobuhara,
	and Yaser Sheikh
	<br>
	In <em>ICCV 2015</em> &nbsp <b> (Oral) </b> <font class="ratio"> - Acceptance ratio: 56/1698~3.3% </font>
 
	<br>
	<a href="http://www.cs.cmu.edu/~hanbyulj/panoptic-studio/ICCV2015_SMC.pdf"> [Paper(PDF)]</a> 
	<a href="http://www.cs.cmu.edu/~hanbyulj/panoptic-studio/ICCV2015_SMC_Supp.pdf"> [Supplementary Material]</a> 

	<a href="http://www.cs.cmu.edu/~hanbyulj/panoptic-studio">[Project Page]</a> 
	<a href="http://domedb.perception.cs.cmu.edu">[Dataset]</a> 
</p>
	</td>
</tr>


<tr>
	<td width="30%">
	<!--img style="max-height: 200px; max-width: 250px;" src="img/CVPR14.jpg" border="0" -->
	<img style="max-height: 200px; max-width: 250px;" src="img/confetti.gif" border="0">
	</td>
	<td>
 <p> <b>MAP Visibility Estimation for Large-Scale Dynamic 3D Reconstruction</b>
	<br>
	<b>Hanbyul Joo</b>, Hyun Soo Park, and Yaser Sheikh
	<br>
	In <em>CVPR 2014</em> &nbsp <b>(Oral)</b> <font class="ratio"> - Acceptance ratio: 104/1807~5.8% </font>
	<br>

	<a href="http://www.cs.cmu.edu/~hanbyulj/14/CVPR_2014_Visibility.pdf"> [Paper(PDF)]</a> 
	<a href="http://www.cs.cmu.edu/~hanbyulj/14/visibility.html"> [Project Page]</a> <a href="http://www.cs.cmu.edu/~hanbyulj/14/visibilityDataset.html">[Dataset]</a> <br>
	
<a href="http://spectrum.ieee.org/tech-talk/computing/software/camerafilled-dome-recreates-full-3d-motion-scenes"><img src="logos/IEEESpectrum.jpeg" height="20"></a>

<a href="http://www.cnet.com/videos/tomorrow-daily-021-new-video-capture-tech-the-rickroll-rickmote-episode-vii-new-x-wing/"><img src="http://upload.wikimedia.org/wikipedia/en/8/8f/Cnetlogo.png" height="30"></a>

<a href="http://www.nbcnews.com/tech/innovation/camera-studded-dome-tracks-your-every-move-precision-n161541"><img src="logos/nbc-news.png" height="15"></a>

<a href="http://news.discovery.com/tech/gear-and-gadgets/dome-of-500-cameras-creates-amazing-3-d-flicks-140724.htm"><img src="logos/discovery.jpg" height="20"></a>

<a href="http://www.engadget.com/2014/07/21/carnegie-motion-capture-dome/"><img src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/bb/Engadget-logo.svg/200px-Engadget-logo.svg.png" height="20"></a>

<a href="http://gizmodo.com/a-dome-packed-with-480-cameras-captures-detailed-3d-ima-1608263411"><img src="http://i.kinja-img.com/gawker-media/image/upload/s--NkOZEtU4--/xxtpkkwu6xvbcaoxjbx2.png" height="13"><a>

<a href="http://www.theverge.com/2014/7/21/5923767/panoptic-studio-3d-motion-capture-carnegie-melon"><img src="logos/Verge.png" height="20"></a>

<a href="http://www.sciencedaily.com/releases/2014/07/140717124950.htm"><img src="https://www.sciencedaily.com/images/sd-logo.png" height="15"></a>

<a href="http://phys.org/news/2014-07-combinehundreds-videos-reconstruct-3d-motion.html"><img src="logos/phyOrg.jpg" height="25"></a>

<a href="http://www.slate.com/articles/video/video/2014/07/panoptic_studio_carnegie_mellon_s_3_d_camera_dome_can_capture_action.html"><img src="http://upload.wikimedia.org/wikipedia/commons/1/13/Slate_logo.png" height="25"></a>

<a href="http://petapixel.com/2014/07/21/researchers-use-480-camera-setup-accurately-capture-3d-motion/"><img src="logos/petapixel.jpg" height="25"></a>

<a href="http://www.gizmag.com/3d-motion-reconstruction-camera-panoptic-dome/33033/"><img src="logos/gizmag.jpeg" height="25"></a>

<a href="http://www.theregister.co.uk/2014/07/22/boffins_fill_a_dome_with_480_cameras_for_3d_motion_capture/"><img src="logos/TheRegisterLogo.jpg" height="20"></a>

<a href="http://www.theengineer.co.uk/electronics/news/3d-motion-captured-without-markers/1018947.article"><img src="logos/theEngineer.png" height="20"></a>

<a href="http://www.popphoto.com/news/2014/07/carnegie-mellon-packs-480-cameras-dome-to-perfectly-track-3d-motion"><img src="logos/PopPhoto.jpg" height="20"></a>

<a href="http://www.eurekalert.org/pub_releases/2014-07/cmu-cmc071714.php"><img src="logos/EurekAlert.jpg" height="20"></a>

<a href="http://www.azorobotics.com/news.aspx?newsID=5985"><img src="logos/AzoRobot.jpg" height="20"></a>

<a href="http://www.slrlounge.com/latest-3d-tech-geodome-captures-every-move-480-cameras"><img src="logos/slrLounge.jpg" height="20"></a>

<a href="http://security-today.com/articles/2014/07/23/panopticon-captures-every-movement-in-3d.aspx"><img src="logos/securityToday.jpg" height="20"></a>

<a href="http://www.cmu.edu/news/stories/archives/2014/july/july17_reconstructing3Dmotion.html"><img src="logos/CMU.jpg" height="40"></a> 


	</td>
</tr>

<tr>
	<td width="30%">
	<img style="max-height: 200px; max-width: 250px;" src="img/icip11_2.jpg" border="0">
	</td>
	<td>
	<p><b>Graph-based Shape Matching for Deformable Objects</b>
	<br>
	<b>Hanbyul Joo</b>,
	Yekeun Jeong, Olivier Duchenne, and In So Kweon
	<br>
	In <em> ICIP 2011</em> 
	<br>
		<a href="http://www.cs.cmu.edu/~hanbyulj/papers/ICIP2011_JOO_FINAL.pdf">
	[Paper(PDF)]
	</a> </p>
</tr>

<tr>
	<td width="30%">
	<img style="max-height: 200px; max-width: 250px;" src="img/icra09.jpg" border="0">
	</td>
	<td>
	<p><b>Graph-Based Robust Shape Matching for Robotic Application</b>
	<br>
	<b>Hanbyul Joo</b>,
	Yekeun Jeong, Olivier Duchenne, Seong-Young Ko, and In So Kweon
	<br>
	In <em>ICRA 2009</em> 
	<br>
	<a href="http://www.cs.cmu.edu/~hanbyulj/papers/ICRA2009.pdf">
	[Paper(PDF)]
	</a> </p>
	</td>
</tr>

<tr>
	<td width="30%">
	<img style="max-height: 200px; max-width: 250px;" src="img/MVA07.jpg" border="0">
	</td>
	<td>
	<p><b>Statistical Background Subtraction Based on the Exact Per-pixel Distributions</b>
	<br>
	Youngbae Hwang, <b>Hanbyul Joo</b>, Jun-sik Kim, and In So Kweon
	<br>
	In <em>IAPR workshop on Machine Vision Applications (MVA) 2007</em> 
	<br>
	<a href="
http://rcv.kaist.ac.kr/~unicorn/paper/hwang_MVA_2007.pdf">
	[Paper(PDF)]
	</a></p>
	</td>
</tr>


</table>
 
<!--img 
src="http://monster.gostats.com/bin/count?a=400436&amp;t=4&amp;i=19&amp;z=" 
style="border-width:0px" alt="Free web counters" /><br / 
<small>since Jan 2007. </small -->
<!-- End GoStats.com Simple HTML based code -->


<h2>Dataset</h2>
<table cellspacing="15">
<tr>
	<td width="30%">
	<a href="http://domedb.perception.cs.cmu.edu"><img style="max-height: 200px; max-width: 250px;" src="img/ExampleResults.jpg" border="0"></a>
	</td>
	<td>
 		<p> <b><a href="http://domedb.perception.cs.cmu.edu">CMU Panoptic Studio Dataset</a></b>
	</td>
</tr>
</table>


<h2>Talks</h2>
<ul>
<li> <p> <b>"The Panoptic Studio: A Massively Multiview System for Social Motion Capture"</b></p></li>
	<ul>
		<li> ICCV Oral Talk, Dec 2015.</li>
		<li> CMU, <a href="http://www.ri.cmu.edu/event_detail.html?event_id=1151&&menu_id=422&event_type=seminars">VASC Seminar</a>, Dec 2015.</li>
		<li> ETH Zurich, Computer Vision and Geometry lab, Oct 2015 (hosted by Prof. Marc Pollefeys).</li>
		<li> Seoul National University, June 2015 (hosted by Prof. Kyoung Mu Lee).</li>
		<li> ETRI, CG Team, May 2015 (hosted by Dr. Seong-Jae Lim).</li>
		<li> KAIST, May 2015 (hosted by Prof. In So Kweon).</li>
	</ul>

<li> <p> <b>"The Panoptic Studio"</b>
	<ul>
		<li> Graduate Seminar, Civil &amp; Environmental Engineering, CMU, Feb 2015 (hosted by Prof. Hae Young Noh).</li>
		<li> People Image Analysis Consortium, CMU, Nov 2014.</li>
		<li> Reality Computing Meetup, Autodesk, Nov 2014.</li>
	</ul>
<li> <p> <b>"MAP Visibility Estimation for Large-Scale Dynamic 3D Reconstruction"</b></li>
	<ul>
		<li> CVPR Oral Talk, June 2014 <a href="http://techtalks.tv/talks/map-visibility-estimation-for-large-scale-dynamic-3d-reconstruction/60293">(link)</a>.</li>
		<li> CMU, <a href="http://www.ri.cmu.edu/event_detail.html?event_id=902&&menu_id=427&event_type=seminars">VASC Seminar</a>, June 2014.</li>

	</ul>

</ul >


<h2>Press Coverage</h2>
<ul>
<p>

<li> <a href="http://www.spiegel.de/netzwelt/gadgets/das-panoptische-studio-computer-entziffern-koerpersprache-a-1068155.html">The panoptic Studio: Computer decipher the secrets of body language</a>, SPIEGEL ONLINE, 2015 (German)
</li>

<li> <a href="http://www.fastcodesign.com/3054561/inside-a-robot-eyeball-science-will-decode-our-body-language">Inside A Robot Eyeball, Science Will Decode Our Body Language</a>, Co.DESIGN, 2015.
</li>

<li> <a href="http://www.wired.it/tv/guarda-riprese-360-gradi-panoptic-studio">Panoptic Studio: The Latest Generation of Motion Capture</a>, WIRED, 2015 (Italian) </li>


<li> <a href="http://www.reuters.com/article/2015/04/29/us-usa-panoptic-studio-idUSKBN0NK09920150429">Motion capture on a whole new level</a>, Reuters, 2015 (Video)  </li>

<li> <a href="http://www.voanews.com/content/new-studio-yields-most-detailed-motion-capture-in-3d/2743347.html">New Studio Yields Most Detailed Motion Capture in 3D</a>, Voice of America, 2015 (Video) <br>  </li>


<!-- li> <a href="http://www.discovery.ca/dailyplanet"> Future Tech: Panoptic Studio</a>, Daily Planet, Discovery Channel Canada, 2015 <br> (TV show, in the linked website, click "Segments" and select "Future tech: Panoptic Studio")--> </li>


<!--li> <a href="http://www.slate.com/articles/video/video/2014/07/panoptic_studio_carnegie_mellon_s_3_d_camera_dome_can_capture_action.html">Freezing Memories in Time: Carnegie Mellon's amazing 3-D "Panoptic Studio"</a>, Slate, 2014  (Video)

<iframe width="560" height="315" src="//www.youtube.com/embed/kEYoiSPGPqA?list=UUYC4ijpFZY_CtdElWFyy-Gg?rel=0;3&amp;autohide=1&amp;showinfo=0" frameborder="0" allowfullscreen></iframe  </li -->



<li> <a href="http://www.cnet.com/videos/tomorrow-daily-021-new-video-capture-tech-the-rickroll-rickmote-episode-vii-new-x-wing/">Tomorrow Daily: New video capture tech, the Rickroll 'Rickmote,' a new X-wing, and more</a>, CNet, 2014 (Video)
<!-- iframe width="560" height="315" src="//www.youtube.com/embed/tpIfotFW-P4?rel=0;3&amp;autohide=1&amp;showinfo=0" frameborder="0" allowfullscreen></iframe --></li>
<li> <a href="http://www.nbcnews.com/tech/innovation/camera-studded-dome-tracks-your-every-move-precision-n161541"> Camera-Studded Dome Tracks Your Every Move With Precision</a>, NBCNews, 2014 </li>
<li> <a href="http://spectrum.ieee.org/tech-talk/computing/software/camerafilled-dome-recreates-full-3d-motion-scenes"> Camera-Filled Dome Recreates Full 3-D Motion Scenes</a>, IEEE Spectrum, 2014</li>
<li> <a href="http://news.discovery.com/tech/gear-and-gadgets/dome-of-500-cameras-creates-amazing-3-d-flicks-140724.htm"> Amazing 3-D Flicks from Dome of 500 Cameras?</a>, Discovery News, 2014</li>
<li> <a href="http://gizmodo.com/a-dome-packed-with-480-cameras-captures-detailed-3d-ima-1608263411">A Dome Packed With 480 Cameras Captures Detailed 3D Images In Motion</a>, Gizmodo, 2014 </li>
<li> <a href="http://www.theverge.com/2014/7/21/5923767/panoptic-studio-3d-motion-capture-carnegie-melon">Scientists build a real Panopticon that captures your every move in 3D</a> The Verge </li>
<li> <a href="http://www.sciencedaily.com/releases/2014/07/140717124950.htm">Hundreds of videos used to reconstruct 3-D motion without markers</a>, ScienceDaily, 2014</li>
<li> <a href="http://phys.org/news/2014-07-combinehundreds-videos-reconstruct-3d-motion.html">Researchers combine hundreds of videos to reconstruct 3D motion without markers</a>, Phys.org, 2014 </li>
<li> <a href="http://www.engadget.com/2014/07/21/carnegie-motion-capture-dome/">Watch a dome full of cameras capture 3D motion in extreme detail</a>, Engadget, 2014 </li>
<li> <a href="http://petapixel.com/2014/07/21/researchers-use-480-camera-setup-accurately-capture-3d-motion/">Researchers Use a 480-Camera Dome to More Accurately Capture 3D Motion</a> PetaPixel, 2014 </li>
<li> <a href="http://www.gizmag.com/3d-motion-reconstruction-camera-panoptic-dome/33033/">Camera-studded dome used to reconstruct 3D motion</a>, Gizmag, 2014</li>
<li> <a href="http://www.theregister.co.uk/2014/07/22/boffins_fill_a_dome_with_480_cameras_for_3d_motion_capture/">Boffins fill a dome with 480 cameras for 3D motion capture</a> Register, 2014  </li>
<li> <a href="http://www.theengineer.co.uk/electronics/news/3d-motion-captured-without-markers/1018947.article">3D motion captured without markers</a>, The Engineer, 2014 </li>
<li> <a href="http://www.popphoto.com/news/2014/07/carnegie-mellon-packs-480-cameras-dome-to-perfectly-track-3d-motion">Carnegie Mellon Packs 480 Cameras In A Dome To Perfectly Track 3D Motion</a>, Popular Photography, 2014 </li>
<li> <a href="http://www.cmu.edu/news/stories/archives/2014/july/july17_reconstructing3Dmotion.html">Carnegie Mellon Combines Hundreds of Videos To Reconstruct 3D Motion Without Use of Markers</a>, CMU News, 2014 </li>
</p></ul>

<h2>Patents</h2>
<ul>
<li> <p><b>Motion capture apparatus and method (Patent No.: US 8805024 B2)</b><br>
<b> Hanbyul Joo</b>, Seong-Jae Lim, Ji-Hyung Lee, Bon-Ki Koo </li>
<li> <p><b>Method for automatic rigging and shape surface transfer of 3D standard mesh model based on muscle and nurbs by using parametric control (Patent No.: US 7171060 B2)</b><br>
Seong Jae Lim, Ho Won Kim, <b>Hanbyul Joo</b>, Bon Ki Koo</li>
<li><p> <b>3D model shape transformation method and apparatus (Patent Application No.: US 20120162217 A1)</b><br> Seong-Jae Lim, <b>Hanbyul Joo</b>, Seung-Uk Yoon, Ji-Hyung Lee, Bon-Ki Koo. </li>
</ul>

</td> </table>
</body>
</html>

