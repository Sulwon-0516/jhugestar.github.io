
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<link rel="stylesheet" type="text/css" href="myStyle.css">
	<title>Panoptic Studio</title>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-50740543-1', 'cmu.edu');
  ga('send', 'pageview');
  </script>
</head>
</p>

<body>
<table width="916", align="center">
  <tr>
  	  
	  <td width="908">
	  <h1> <center> The Panoptic Studio: A Massively Multiview System for <br> Social Motion Capture (in ICCV 2015)</center> </h1>
        <p align = "center"><font size = "4">  <a href="https://jhugestar.github.io">Hanbyul Joo</a>, Hao Liu, Lei Tan, Lin Gui, Bart Nabbe <br> Iain Matthews, Takeo Kanade, Shohei Nobuhara, and <a href="http://www.cs.cmu.edu/~yaser/">Yaser Sheikh</a></font></p>

	<p align = "center"><font size = "4", font="font" face = "Georgia"> Carnegie Mellon University </p>

	<h2> Notes</h2>
	<ul>
	<li> Our brand new <b>Panoptic Studio dataset</b> is open: <a href="http://domedb.perception.cs.cmu.edu">Panoptic Studio dataset website</a>.</li>
	<li> An extended version of the method is available in <a href="https://arxiv.org/abs/1612.03153">arXiv</a> (currently submitted to a journal).</li>
	<li> The following page is describing our work published on ICCV 2015. </li>
	</ul>

	<h2></h2>


	<iframe width="853" height="480" src="https://www.youtube.com/embed/H0icc3Pg_Ig?rel=0" frameborder="0" allowfullscreen></iframe>

	<!-- img src="Resized_resized_domeImage.png" width="853">
	<p align="center"> The Panoptic Studio exterior and interior </p-->
	<!-- iframe width="853" height="480" src="http://www.youtube.com/embed/iKPcj2hGO_8" frameborder="0" allowfullscreen></iframe -->
	<!-- p align = "center"><img src="result1.jpg" alt="" width="600" /></p >
	<p align = "center"><font size = "3", font="font" face = "Georgia">Figure 1: 
We reconstruct 3D trajectories in real world scenes in the presence of significant occlusion, large displacement, and topological
change. The colors code the length of trajectories. </b></font></p -->

	<h2>Abstract</h2>
	<p align = "justify">
We present an approach to capture the 3D structure and motion of a group of people engaged in a social interaction.
The core challenges in capturing social interactions are: (1) occlusion is functional and frequent; (2) subtle motion
needs to be measured over a space large enough to host a social group; and (3) human appearance and con-
figuration variation is immense. The Panoptic Studio is a system organized around the thesis that social interactions
should be measured through the perceptual integration of a large variety of view points. We present a modularized
system designed around this principle, consisting of integrated structural, hardware, and software innovations. The
system takes, as input, 480 synchronized video streams of multiple people engaged in social activities, and produces,
as output, the labeled time-varying 3D structure of anatomical landmarks on individuals in the space. The algorithmic
contributions include a hierarchical approach for generating skeletal trajectory proposals, and an optimization
framework for skeletal reconstruction with trajectory reassociation. 
 
</p>

	<h2>Publication</h2>
	<p>
	Panoptic Studio: A Massively Multiview System for Social Motion Capture 
	<br> Hanbyul Joo, Hao Liu, Lei Tan, Lin Gui, Bart Nabbe, Iain Matthews, Takeo Kanade, Shohei Nobuhara, Yaser Sheikh
	<br> In ICCV 2015. <b> (Oral Presentation) </b>  <br>
	<a href="ICCV2015_SMC.pdf"> [Paper(PDF)]</a> 
	<a href="ICCV2015_SMC_Supp.pdf">[Supplementary Material]</a>  
	<a href="PanopticStudio_ICCV15.pdf">[Slide(pdf)]</a>  
	<a href="bib"> [BibTex]</a>  </p>

	<h2>Oral Talk</h2>
	<a href='http://videolectures.net/iccv2015_joo_panoptic_studio/'>
	<img src='http://videolectures.net/iccv2015_joo_panoptic_studio/thumb.jpg' border=0/></a><br/>
		

	<!--h2>Dataset</h2>
	<p>All the data will be available in our <a href="http://cs.cmu.edu/~panoptic-studio">Panoptic Studio dataset website</a>. Please check the website.</p-->

	<h2>Videos</h2>
	<iframe width="853" height="480" src="https://www.youtube.com/embed/zQt6g-Jel7M?rel=0;3&amp;autohide=1&amp;showinfo=0" frameborder="0" allowfullscreen></iframe>
	<p align="center"> Social Motion Capture (Joo et al., ICCV 2015)</p> <br>
	<br>

	<!--iframe width="853" height="480" src="http://www.youtube.com/embed/LaHTjBWago8?rel=0;3&amp;autohide=1&amp;showinfo=0" frameborder="0" allowfullscreen></iframe>
	<p align="center"> Full Length Video </p-->
	<!--iframe width="853" height="480" src="//www.youtube.com/embed/TrYo3c1mjgo?rel=0;3&amp;autohide=1&amp;showinfo=0" frameborder="0" allowfullscreen></iframe>
	<p align="center"> Detailed Views of Selected Trajectories </p--> 
	<!--a href="./CVPR_2014_Visibility_shortClip_Final.mp4">Teaser Video (1280x720, 80.M)</a> <br> 
	<a href="./CVPR_2014_Visibility_FullLength_Final.mp4">Full Length Video (1280x720, 290.6M)</a-->
	

	<h2>Acknowledgements</h2>
	<p> This research is supported by the National Science Foundation under Grants No. 1353120 and 1029679, and in part using an ONR grant 11628301
</p>
 	</td>
  </tr>
</table>
</body>
</html>

